{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2b95e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661    1\n",
      "122    0\n",
      "113    0\n",
      "14     1\n",
      "529    0\n",
      "103    0\n",
      "338    1\n",
      "588    1\n",
      "395    0\n",
      "204    0\n",
      "31     1\n",
      "546    1\n",
      "278    0\n",
      "593    0\n",
      "737    0\n",
      "202    0\n",
      "175    1\n",
      "55     0\n",
      "479    0\n",
      "365    0\n",
      "417    1\n",
      "577    1\n",
      "172    0\n",
      "352    0\n",
      "27     0\n",
      "605    0\n",
      "239    0\n",
      "744    0\n",
      "79     0\n",
      "496    0\n",
      "285    0\n",
      "422    0\n",
      "640    0\n",
      "374    0\n",
      "385    0\n",
      "404    1\n",
      "648    1\n",
      "500    0\n",
      "575    0\n",
      "Name: Outcome, dtype: int64\n",
      "Epoch 1/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5336 - val_loss: 0.6945 - val_accuracy: 0.6410\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.6543 - val_loss: 0.6873 - val_accuracy: 0.6923\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.6708 - val_loss: 0.6812 - val_accuracy: 0.6923\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.6680 - val_loss: 0.6754 - val_accuracy: 0.6667\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.6612 - val_loss: 0.6701 - val_accuracy: 0.6667\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.6529 - val_loss: 0.6636 - val_accuracy: 0.6667\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.6475 - val_loss: 0.6572 - val_accuracy: 0.6923\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6447 - val_loss: 0.6500 - val_accuracy: 0.6923\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6488 - val_loss: 0.6416 - val_accuracy: 0.7179\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6502 - val_loss: 0.6343 - val_accuracy: 0.7179\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6502 - val_loss: 0.6263 - val_accuracy: 0.7179\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6488 - val_loss: 0.6172 - val_accuracy: 0.7179\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6475 - val_loss: 0.6079 - val_accuracy: 0.7179\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6475 - val_loss: 0.5991 - val_accuracy: 0.7179\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.6488 - val_loss: 0.5890 - val_accuracy: 0.7179\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.6488 - val_loss: 0.5784 - val_accuracy: 0.7179\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6488 - val_loss: 0.5681 - val_accuracy: 0.7179\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.6488 - val_loss: 0.5580 - val_accuracy: 0.7179\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.6488 - val_loss: 0.5464 - val_accuracy: 0.7179\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6475 - val_loss: 0.5378 - val_accuracy: 0.6667\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.6502 - val_loss: 0.5282 - val_accuracy: 0.6667\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.6571 - val_loss: 0.5200 - val_accuracy: 0.6667\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.6749 - val_loss: 0.5139 - val_accuracy: 0.7949\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.6790 - val_loss: 0.5051 - val_accuracy: 0.8205\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5459 - accuracy: 0.6872 - val_loss: 0.4998 - val_accuracy: 0.8205\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.6927 - val_loss: 0.4926 - val_accuracy: 0.8462\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.6968 - val_loss: 0.4863 - val_accuracy: 0.8462\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.6968 - val_loss: 0.4830 - val_accuracy: 0.8462\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.6996 - val_loss: 0.4767 - val_accuracy: 0.8462\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7051 - val_loss: 0.4711 - val_accuracy: 0.8462\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7078 - val_loss: 0.4694 - val_accuracy: 0.8205\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7160 - val_loss: 0.4641 - val_accuracy: 0.8205\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7174 - val_loss: 0.4591 - val_accuracy: 0.8205\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7188 - val_loss: 0.4564 - val_accuracy: 0.7949\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7202 - val_loss: 0.4524 - val_accuracy: 0.7949\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7202 - val_loss: 0.4481 - val_accuracy: 0.7949\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7202 - val_loss: 0.4452 - val_accuracy: 0.7949\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7215 - val_loss: 0.4426 - val_accuracy: 0.7949\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7202 - val_loss: 0.4390 - val_accuracy: 0.7949\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7202 - val_loss: 0.4387 - val_accuracy: 0.7949\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7188 - val_loss: 0.4340 - val_accuracy: 0.8205\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7215 - val_loss: 0.4308 - val_accuracy: 0.8205\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7325 - val_loss: 0.4336 - val_accuracy: 0.8205\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7325 - val_loss: 0.4290 - val_accuracy: 0.8205\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7380 - val_loss: 0.4300 - val_accuracy: 0.8205\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7380 - val_loss: 0.4262 - val_accuracy: 0.8205\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7380 - val_loss: 0.4228 - val_accuracy: 0.8205\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7407 - val_loss: 0.4222 - val_accuracy: 0.8205\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7380 - val_loss: 0.4218 - val_accuracy: 0.8205\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7394 - val_loss: 0.4214 - val_accuracy: 0.8205\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7407 - val_loss: 0.4184 - val_accuracy: 0.8205\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7421 - val_loss: 0.4166 - val_accuracy: 0.8205\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7435 - val_loss: 0.4162 - val_accuracy: 0.8205\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7462 - val_loss: 0.4171 - val_accuracy: 0.8205\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7449 - val_loss: 0.4122 - val_accuracy: 0.8205\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7490 - val_loss: 0.4109 - val_accuracy: 0.8205\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7476 - val_loss: 0.4122 - val_accuracy: 0.8205\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7517 - val_loss: 0.4101 - val_accuracy: 0.8205\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7503 - val_loss: 0.4097 - val_accuracy: 0.8205\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7503 - val_loss: 0.4102 - val_accuracy: 0.8205\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7545 - val_loss: 0.4097 - val_accuracy: 0.8205\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7503 - val_loss: 0.4112 - val_accuracy: 0.8205\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7531 - val_loss: 0.4063 - val_accuracy: 0.8205\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7545 - val_loss: 0.4064 - val_accuracy: 0.8205\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7531 - val_loss: 0.4076 - val_accuracy: 0.8205\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7531 - val_loss: 0.4060 - val_accuracy: 0.8205\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7531 - val_loss: 0.4032 - val_accuracy: 0.8205\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7545 - val_loss: 0.4046 - val_accuracy: 0.8205\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7517 - val_loss: 0.4054 - val_accuracy: 0.8205\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7572 - val_loss: 0.4006 - val_accuracy: 0.8462\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7517 - val_loss: 0.4008 - val_accuracy: 0.8205\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7545 - val_loss: 0.3986 - val_accuracy: 0.8205\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7572 - val_loss: 0.3954 - val_accuracy: 0.8462\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7572 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7572 - val_loss: 0.3921 - val_accuracy: 0.8462\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7572 - val_loss: 0.3926 - val_accuracy: 0.8462\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7572 - val_loss: 0.3898 - val_accuracy: 0.8462\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7545 - val_loss: 0.3919 - val_accuracy: 0.8718\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7572 - val_loss: 0.3884 - val_accuracy: 0.8718\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7641 - val_loss: 0.3831 - val_accuracy: 0.8462\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7627 - val_loss: 0.3839 - val_accuracy: 0.8718\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7641 - val_loss: 0.3815 - val_accuracy: 0.8718\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7641 - val_loss: 0.3832 - val_accuracy: 0.8718\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7682 - val_loss: 0.3797 - val_accuracy: 0.8718\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7682 - val_loss: 0.3805 - val_accuracy: 0.8718\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7627 - val_loss: 0.3825 - val_accuracy: 0.8718\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7641 - val_loss: 0.3754 - val_accuracy: 0.8718\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7641 - val_loss: 0.3768 - val_accuracy: 0.8718\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7641 - val_loss: 0.3767 - val_accuracy: 0.8718\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7641 - val_loss: 0.3738 - val_accuracy: 0.8718\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7641 - val_loss: 0.3742 - val_accuracy: 0.8718\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7654 - val_loss: 0.3744 - val_accuracy: 0.8718\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7641 - val_loss: 0.3710 - val_accuracy: 0.8718\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7654 - val_loss: 0.3735 - val_accuracy: 0.8718\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7627 - val_loss: 0.3755 - val_accuracy: 0.8718\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7641 - val_loss: 0.3689 - val_accuracy: 0.8718\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7682 - val_loss: 0.3682 - val_accuracy: 0.8718\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7668 - val_loss: 0.3684 - val_accuracy: 0.8718\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7695 - val_loss: 0.3665 - val_accuracy: 0.8718\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7682 - val_loss: 0.3699 - val_accuracy: 0.8718\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7682 - val_loss: 0.3682 - val_accuracy: 0.8718\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7737 - val_loss: 0.3656 - val_accuracy: 0.8718\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7723 - val_loss: 0.3660 - val_accuracy: 0.8718\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7695 - val_loss: 0.3699 - val_accuracy: 0.8718\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7709 - val_loss: 0.3630 - val_accuracy: 0.8718\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7709 - val_loss: 0.3633 - val_accuracy: 0.8718\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7695 - val_loss: 0.3657 - val_accuracy: 0.8718\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7709 - val_loss: 0.3646 - val_accuracy: 0.8718\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7695 - val_loss: 0.3663 - val_accuracy: 0.8718\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7682 - val_loss: 0.3621 - val_accuracy: 0.8718\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7737 - val_loss: 0.3618 - val_accuracy: 0.8718\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7723 - val_loss: 0.3630 - val_accuracy: 0.8718\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7723 - val_loss: 0.3592 - val_accuracy: 0.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7709 - val_loss: 0.3604 - val_accuracy: 0.8718\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7723 - val_loss: 0.3608 - val_accuracy: 0.8718\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7737 - val_loss: 0.3613 - val_accuracy: 0.8718\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7737 - val_loss: 0.3608 - val_accuracy: 0.8718\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7791 - val_loss: 0.3594 - val_accuracy: 0.8718\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7805 - val_loss: 0.3603 - val_accuracy: 0.8718\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7819 - val_loss: 0.3592 - val_accuracy: 0.8718\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7819 - val_loss: 0.3581 - val_accuracy: 0.8718\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7805 - val_loss: 0.3591 - val_accuracy: 0.8718\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7833 - val_loss: 0.3594 - val_accuracy: 0.8718\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7860 - val_loss: 0.3562 - val_accuracy: 0.8718\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7901 - val_loss: 0.3557 - val_accuracy: 0.8718\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7860 - val_loss: 0.3573 - val_accuracy: 0.8718\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7860 - val_loss: 0.3565 - val_accuracy: 0.8718\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7846 - val_loss: 0.3565 - val_accuracy: 0.8718\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7833 - val_loss: 0.3548 - val_accuracy: 0.8718\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7846 - val_loss: 0.3527 - val_accuracy: 0.8718\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7846 - val_loss: 0.3551 - val_accuracy: 0.8718\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7846 - val_loss: 0.3553 - val_accuracy: 0.8718\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7846 - val_loss: 0.3528 - val_accuracy: 0.8718\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7874 - val_loss: 0.3524 - val_accuracy: 0.8718\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7860 - val_loss: 0.3532 - val_accuracy: 0.8718\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7819 - val_loss: 0.3555 - val_accuracy: 0.8718\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7846 - val_loss: 0.3509 - val_accuracy: 0.8718\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7860 - val_loss: 0.3493 - val_accuracy: 0.8718\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7860 - val_loss: 0.3515 - val_accuracy: 0.8718\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7860 - val_loss: 0.3497 - val_accuracy: 0.8718\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7846 - val_loss: 0.3534 - val_accuracy: 0.8718\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7846 - val_loss: 0.3493 - val_accuracy: 0.8718\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7846 - val_loss: 0.3484 - val_accuracy: 0.8718\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7874 - val_loss: 0.3483 - val_accuracy: 0.8718\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7860 - val_loss: 0.3504 - val_accuracy: 0.8718\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7860 - val_loss: 0.3482 - val_accuracy: 0.8718\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7874 - val_loss: 0.3465 - val_accuracy: 0.8718\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7860 - val_loss: 0.3506 - val_accuracy: 0.8718\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7860 - val_loss: 0.3485 - val_accuracy: 0.8718\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7874 - val_loss: 0.3467 - val_accuracy: 0.8718\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7860 - val_loss: 0.3478 - val_accuracy: 0.8718\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7860 - val_loss: 0.3464 - val_accuracy: 0.8718\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7860 - val_loss: 0.3469 - val_accuracy: 0.8718\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7846 - val_loss: 0.3488 - val_accuracy: 0.8718\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7860 - val_loss: 0.3471 - val_accuracy: 0.8718\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7860 - val_loss: 0.3464 - val_accuracy: 0.8718\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7860 - val_loss: 0.3472 - val_accuracy: 0.8718\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7860 - val_loss: 0.3470 - val_accuracy: 0.8718\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7846 - val_loss: 0.3452 - val_accuracy: 0.8718\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7874 - val_loss: 0.3457 - val_accuracy: 0.8718\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7860 - val_loss: 0.3455 - val_accuracy: 0.8718\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7846 - val_loss: 0.3486 - val_accuracy: 0.8718\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7860 - val_loss: 0.3448 - val_accuracy: 0.8718\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7860 - val_loss: 0.3445 - val_accuracy: 0.8718\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7874 - val_loss: 0.3437 - val_accuracy: 0.8718\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7860 - val_loss: 0.3446 - val_accuracy: 0.8718\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7860 - val_loss: 0.3430 - val_accuracy: 0.8718\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7860 - val_loss: 0.3461 - val_accuracy: 0.8718\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7860 - val_loss: 0.3451 - val_accuracy: 0.8718\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7888 - val_loss: 0.3415 - val_accuracy: 0.8718\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7860 - val_loss: 0.3475 - val_accuracy: 0.8718\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7860 - val_loss: 0.3458 - val_accuracy: 0.8718\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7860 - val_loss: 0.3412 - val_accuracy: 0.8718\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7860 - val_loss: 0.3434 - val_accuracy: 0.8718\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7860 - val_loss: 0.3451 - val_accuracy: 0.8718\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7860 - val_loss: 0.3431 - val_accuracy: 0.8718\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7860 - val_loss: 0.3435 - val_accuracy: 0.8718\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7860 - val_loss: 0.3424 - val_accuracy: 0.8718\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7846 - val_loss: 0.3452 - val_accuracy: 0.8718\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7860 - val_loss: 0.3448 - val_accuracy: 0.8718\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7860 - val_loss: 0.3439 - val_accuracy: 0.8718\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7860 - val_loss: 0.3440 - val_accuracy: 0.8718\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7860 - val_loss: 0.3457 - val_accuracy: 0.8718\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7860 - val_loss: 0.3451 - val_accuracy: 0.8718\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7860 - val_loss: 0.3465 - val_accuracy: 0.8718\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7860 - val_loss: 0.3463 - val_accuracy: 0.8718\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7860 - val_loss: 0.3450 - val_accuracy: 0.8718\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7860 - val_loss: 0.3455 - val_accuracy: 0.8718\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7860 - val_loss: 0.3439 - val_accuracy: 0.8718\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7874 - val_loss: 0.3490 - val_accuracy: 0.8718\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7874 - val_loss: 0.3477 - val_accuracy: 0.8718\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7860 - val_loss: 0.3469 - val_accuracy: 0.8718\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7860 - val_loss: 0.3466 - val_accuracy: 0.8718\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7874 - val_loss: 0.3484 - val_accuracy: 0.8718\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7860 - val_loss: 0.3468 - val_accuracy: 0.8718\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7860 - val_loss: 0.3486 - val_accuracy: 0.8718\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7860 - val_loss: 0.3475 - val_accuracy: 0.8974\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7860 - val_loss: 0.3497 - val_accuracy: 0.8718\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7860 - val_loss: 0.3479 - val_accuracy: 0.8718\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7874 - val_loss: 0.3451 - val_accuracy: 0.8974\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7901 - val_loss: 0.3473 - val_accuracy: 0.8974\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7888 - val_loss: 0.3471 - val_accuracy: 0.8974\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7888 - val_loss: 0.3490 - val_accuracy: 0.8718\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7874 - val_loss: 0.3503 - val_accuracy: 0.8718\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7888 - val_loss: 0.3480 - val_accuracy: 0.8974\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7874 - val_loss: 0.3483 - val_accuracy: 0.8974\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7901 - val_loss: 0.3482 - val_accuracy: 0.8974\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7888 - val_loss: 0.3518 - val_accuracy: 0.8718\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7901 - val_loss: 0.3512 - val_accuracy: 0.8974\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7888 - val_loss: 0.3527 - val_accuracy: 0.8974\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7874 - val_loss: 0.3493 - val_accuracy: 0.8974\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7874 - val_loss: 0.3502 - val_accuracy: 0.8974\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7874 - val_loss: 0.3493 - val_accuracy: 0.8974\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7901 - val_loss: 0.3500 - val_accuracy: 0.8974\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7888 - val_loss: 0.3490 - val_accuracy: 0.8974\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7901 - val_loss: 0.3515 - val_accuracy: 0.8974\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7888 - val_loss: 0.3497 - val_accuracy: 0.8974\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7874 - val_loss: 0.3506 - val_accuracy: 0.8974\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7888 - val_loss: 0.3501 - val_accuracy: 0.8974\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7846 - val_loss: 0.3518 - val_accuracy: 0.8974\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7860 - val_loss: 0.3509 - val_accuracy: 0.8974\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7915 - val_loss: 0.3508 - val_accuracy: 0.8974\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7888 - val_loss: 0.3523 - val_accuracy: 0.8974\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7888 - val_loss: 0.3539 - val_accuracy: 0.8974\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7874 - val_loss: 0.3523 - val_accuracy: 0.8974\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7901 - val_loss: 0.3499 - val_accuracy: 0.8974\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7915 - val_loss: 0.3526 - val_accuracy: 0.8974\n",
      "Epoch 228/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7874 - val_loss: 0.3540 - val_accuracy: 0.8974\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7874 - val_loss: 0.3507 - val_accuracy: 0.8974\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7846 - val_loss: 0.3546 - val_accuracy: 0.8974\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7874 - val_loss: 0.3529 - val_accuracy: 0.8974\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7915 - val_loss: 0.3510 - val_accuracy: 0.8974\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7901 - val_loss: 0.3547 - val_accuracy: 0.8974\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7888 - val_loss: 0.3518 - val_accuracy: 0.8974\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7846 - val_loss: 0.3585 - val_accuracy: 0.8974\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7874 - val_loss: 0.3535 - val_accuracy: 0.8974\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7901 - val_loss: 0.3532 - val_accuracy: 0.8974\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7901 - val_loss: 0.3546 - val_accuracy: 0.8974\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7901 - val_loss: 0.3553 - val_accuracy: 0.8974\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7929 - val_loss: 0.3565 - val_accuracy: 0.8974\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7956 - val_loss: 0.3547 - val_accuracy: 0.8974\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7929 - val_loss: 0.3572 - val_accuracy: 0.8974\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7888 - val_loss: 0.3566 - val_accuracy: 0.8974\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7956 - val_loss: 0.3562 - val_accuracy: 0.8974\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7915 - val_loss: 0.3580 - val_accuracy: 0.8974\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7874 - val_loss: 0.3566 - val_accuracy: 0.8974\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7929 - val_loss: 0.3562 - val_accuracy: 0.8974\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7901 - val_loss: 0.3579 - val_accuracy: 0.8974\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7915 - val_loss: 0.3547 - val_accuracy: 0.8974\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7929 - val_loss: 0.3575 - val_accuracy: 0.8974\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7888 - val_loss: 0.3576 - val_accuracy: 0.8974\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7888 - val_loss: 0.3564 - val_accuracy: 0.8974\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7915 - val_loss: 0.3551 - val_accuracy: 0.8974\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7888 - val_loss: 0.3569 - val_accuracy: 0.8974\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7888 - val_loss: 0.3558 - val_accuracy: 0.8974\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7888 - val_loss: 0.3549 - val_accuracy: 0.8974\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7888 - val_loss: 0.3569 - val_accuracy: 0.8974\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7915 - val_loss: 0.3545 - val_accuracy: 0.8974\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7942 - val_loss: 0.3549 - val_accuracy: 0.8974\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7888 - val_loss: 0.3561 - val_accuracy: 0.8974\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7888 - val_loss: 0.3557 - val_accuracy: 0.8974\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7874 - val_loss: 0.3556 - val_accuracy: 0.8974\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7888 - val_loss: 0.3556 - val_accuracy: 0.8974\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7888 - val_loss: 0.3543 - val_accuracy: 0.8974\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7860 - val_loss: 0.3555 - val_accuracy: 0.8974\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7929 - val_loss: 0.3536 - val_accuracy: 0.8974\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7901 - val_loss: 0.3539 - val_accuracy: 0.8974\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7874 - val_loss: 0.3561 - val_accuracy: 0.8974\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7874 - val_loss: 0.3550 - val_accuracy: 0.8974\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7942 - val_loss: 0.3548 - val_accuracy: 0.8974\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7874 - val_loss: 0.3548 - val_accuracy: 0.8974\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7888 - val_loss: 0.3536 - val_accuracy: 0.8974\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7874 - val_loss: 0.3546 - val_accuracy: 0.8974\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7860 - val_loss: 0.3543 - val_accuracy: 0.8974\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7888 - val_loss: 0.3527 - val_accuracy: 0.8974\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7874 - val_loss: 0.3548 - val_accuracy: 0.8974\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7860 - val_loss: 0.3543 - val_accuracy: 0.8974\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7888 - val_loss: 0.3516 - val_accuracy: 0.8974\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7915 - val_loss: 0.3519 - val_accuracy: 0.8974\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7860 - val_loss: 0.3547 - val_accuracy: 0.8974\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7846 - val_loss: 0.3525 - val_accuracy: 0.8974\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7929 - val_loss: 0.3506 - val_accuracy: 0.8974\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7888 - val_loss: 0.3530 - val_accuracy: 0.8974\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7860 - val_loss: 0.3522 - val_accuracy: 0.8974\n",
      "Epoch 285/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7874 - val_loss: 0.3519 - val_accuracy: 0.8974\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7860 - val_loss: 0.3541 - val_accuracy: 0.8974\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7888 - val_loss: 0.3498 - val_accuracy: 0.8974\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7901 - val_loss: 0.3511 - val_accuracy: 0.8974\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7860 - val_loss: 0.3520 - val_accuracy: 0.8974\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7860 - val_loss: 0.3504 - val_accuracy: 0.8974\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7888 - val_loss: 0.3512 - val_accuracy: 0.8974\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7874 - val_loss: 0.3505 - val_accuracy: 0.8974\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7860 - val_loss: 0.3507 - val_accuracy: 0.8974\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7846 - val_loss: 0.3500 - val_accuracy: 0.8974\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7860 - val_loss: 0.3497 - val_accuracy: 0.8974\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7833 - val_loss: 0.3523 - val_accuracy: 0.8974\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7860 - val_loss: 0.3499 - val_accuracy: 0.8974\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7833 - val_loss: 0.3500 - val_accuracy: 0.8974\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7874 - val_loss: 0.3481 - val_accuracy: 0.8974\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7833 - val_loss: 0.3489 - val_accuracy: 0.8974\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7846 - val_loss: 0.3482 - val_accuracy: 0.8974\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7874 - val_loss: 0.3481 - val_accuracy: 0.8974\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7846 - val_loss: 0.3487 - val_accuracy: 0.8974\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7874 - val_loss: 0.3470 - val_accuracy: 0.8974\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7860 - val_loss: 0.3486 - val_accuracy: 0.8974\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7860 - val_loss: 0.3470 - val_accuracy: 0.8974\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7833 - val_loss: 0.3471 - val_accuracy: 0.8974\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7833 - val_loss: 0.3468 - val_accuracy: 0.8974\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7833 - val_loss: 0.3480 - val_accuracy: 0.8974\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7888 - val_loss: 0.3467 - val_accuracy: 0.8974\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7860 - val_loss: 0.3469 - val_accuracy: 0.8974\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7833 - val_loss: 0.3460 - val_accuracy: 0.9231\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7888 - val_loss: 0.3470 - val_accuracy: 0.8974\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7846 - val_loss: 0.3463 - val_accuracy: 0.8974\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7860 - val_loss: 0.3446 - val_accuracy: 0.9231\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7860 - val_loss: 0.3467 - val_accuracy: 0.8974\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7901 - val_loss: 0.3445 - val_accuracy: 0.9231\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7860 - val_loss: 0.3450 - val_accuracy: 0.8974\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7833 - val_loss: 0.3461 - val_accuracy: 0.8974\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7846 - val_loss: 0.3455 - val_accuracy: 0.9231\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7860 - val_loss: 0.3449 - val_accuracy: 0.8974\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7846 - val_loss: 0.3441 - val_accuracy: 0.9231\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7846 - val_loss: 0.3432 - val_accuracy: 0.9231\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7846 - val_loss: 0.3447 - val_accuracy: 0.8974\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7846 - val_loss: 0.3438 - val_accuracy: 0.9231\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7833 - val_loss: 0.3446 - val_accuracy: 0.8974\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7833 - val_loss: 0.3433 - val_accuracy: 0.9231\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7860 - val_loss: 0.3435 - val_accuracy: 0.9231\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7846 - val_loss: 0.3428 - val_accuracy: 0.9231\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7860 - val_loss: 0.3419 - val_accuracy: 0.9231\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7846 - val_loss: 0.3435 - val_accuracy: 0.9231\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7846 - val_loss: 0.3439 - val_accuracy: 0.8974\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7833 - val_loss: 0.3435 - val_accuracy: 0.9231\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7846 - val_loss: 0.3421 - val_accuracy: 0.9231\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7846 - val_loss: 0.3416 - val_accuracy: 0.9231\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7915 - val_loss: 0.3414 - val_accuracy: 0.9231\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7846 - val_loss: 0.3442 - val_accuracy: 0.8974\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7833 - val_loss: 0.3426 - val_accuracy: 0.8974\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7860 - val_loss: 0.3414 - val_accuracy: 0.9231\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7860 - val_loss: 0.3417 - val_accuracy: 0.9231\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7860 - val_loss: 0.3437 - val_accuracy: 0.8974\n",
      "Epoch 342/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7819 - val_loss: 0.3417 - val_accuracy: 0.8974\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7846 - val_loss: 0.3413 - val_accuracy: 0.9231\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7860 - val_loss: 0.3429 - val_accuracy: 0.8974\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7874 - val_loss: 0.3410 - val_accuracy: 0.9231\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7833 - val_loss: 0.3407 - val_accuracy: 0.9231\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7833 - val_loss: 0.3416 - val_accuracy: 0.9231\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7860 - val_loss: 0.3409 - val_accuracy: 0.9231\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7846 - val_loss: 0.3404 - val_accuracy: 0.9231\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7819 - val_loss: 0.3409 - val_accuracy: 0.9231\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7819 - val_loss: 0.3411 - val_accuracy: 0.9231\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7860 - val_loss: 0.3405 - val_accuracy: 0.9231\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7860 - val_loss: 0.3399 - val_accuracy: 0.8974\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7901 - val_loss: 0.3402 - val_accuracy: 0.8974\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7846 - val_loss: 0.3430 - val_accuracy: 0.8974\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7833 - val_loss: 0.3405 - val_accuracy: 0.8974\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7846 - val_loss: 0.3406 - val_accuracy: 0.8974\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7874 - val_loss: 0.3397 - val_accuracy: 0.8974\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7874 - val_loss: 0.3412 - val_accuracy: 0.8974\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7860 - val_loss: 0.3414 - val_accuracy: 0.8718\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7860 - val_loss: 0.3408 - val_accuracy: 0.8718\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7888 - val_loss: 0.3422 - val_accuracy: 0.8974\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7860 - val_loss: 0.3397 - val_accuracy: 0.8974\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7860 - val_loss: 0.3395 - val_accuracy: 0.8974\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7874 - val_loss: 0.3404 - val_accuracy: 0.8974\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7888 - val_loss: 0.3398 - val_accuracy: 0.8974\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7860 - val_loss: 0.3396 - val_accuracy: 0.8718\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7860 - val_loss: 0.3409 - val_accuracy: 0.8718\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7901 - val_loss: 0.3395 - val_accuracy: 0.8974\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7888 - val_loss: 0.3396 - val_accuracy: 0.8974\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7888 - val_loss: 0.3385 - val_accuracy: 0.8974\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7901 - val_loss: 0.3382 - val_accuracy: 0.8974\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7888 - val_loss: 0.3395 - val_accuracy: 0.8974\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7833 - val_loss: 0.3412 - val_accuracy: 0.8974\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7874 - val_loss: 0.3377 - val_accuracy: 0.8974\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7874 - val_loss: 0.3397 - val_accuracy: 0.8974\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7874 - val_loss: 0.3381 - val_accuracy: 0.8974\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7874 - val_loss: 0.3389 - val_accuracy: 0.8974\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7860 - val_loss: 0.3371 - val_accuracy: 0.8974\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7860 - val_loss: 0.3379 - val_accuracy: 0.8974\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7888 - val_loss: 0.3375 - val_accuracy: 0.8974\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7888 - val_loss: 0.3377 - val_accuracy: 0.8974\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7846 - val_loss: 0.3377 - val_accuracy: 0.8974\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7888 - val_loss: 0.3360 - val_accuracy: 0.8974\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7901 - val_loss: 0.3368 - val_accuracy: 0.9231\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7888 - val_loss: 0.3370 - val_accuracy: 0.9231\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7874 - val_loss: 0.3363 - val_accuracy: 0.8974\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7915 - val_loss: 0.3359 - val_accuracy: 0.8974\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7888 - val_loss: 0.3375 - val_accuracy: 0.8974\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7901 - val_loss: 0.3365 - val_accuracy: 0.8974\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7874 - val_loss: 0.3355 - val_accuracy: 0.8974\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7901 - val_loss: 0.3355 - val_accuracy: 0.8974\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7888 - val_loss: 0.3365 - val_accuracy: 0.8974\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7901 - val_loss: 0.3337 - val_accuracy: 0.8974\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7901 - val_loss: 0.3360 - val_accuracy: 0.8974\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7860 - val_loss: 0.3351 - val_accuracy: 0.8974\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7888 - val_loss: 0.3352 - val_accuracy: 0.8974\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7874 - val_loss: 0.3353 - val_accuracy: 0.8974\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7888 - val_loss: 0.3343 - val_accuracy: 0.8974\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7901 - val_loss: 0.3365 - val_accuracy: 0.8974\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7874 - val_loss: 0.3354 - val_accuracy: 0.8974\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7874 - val_loss: 0.3354 - val_accuracy: 0.8974\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7915 - val_loss: 0.3343 - val_accuracy: 0.8974\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7860 - val_loss: 0.3365 - val_accuracy: 0.8974\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7888 - val_loss: 0.3345 - val_accuracy: 0.8974\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7901 - val_loss: 0.3351 - val_accuracy: 0.8974\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7915 - val_loss: 0.3366 - val_accuracy: 0.8974\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7874 - val_loss: 0.3359 - val_accuracy: 0.8974\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7874 - val_loss: 0.3352 - val_accuracy: 0.8974\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7888 - val_loss: 0.3344 - val_accuracy: 0.8974\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7888 - val_loss: 0.3345 - val_accuracy: 0.8974\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7915 - val_loss: 0.3355 - val_accuracy: 0.8974\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7901 - val_loss: 0.3353 - val_accuracy: 0.8974\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7888 - val_loss: 0.3351 - val_accuracy: 0.8974\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7901 - val_loss: 0.3344 - val_accuracy: 0.8974\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7888 - val_loss: 0.3342 - val_accuracy: 0.8974\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7888 - val_loss: 0.3339 - val_accuracy: 0.8974\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7888 - val_loss: 0.3362 - val_accuracy: 0.8974\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7901 - val_loss: 0.3362 - val_accuracy: 0.8974\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7901 - val_loss: 0.3330 - val_accuracy: 0.8974\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7874 - val_loss: 0.3336 - val_accuracy: 0.8974\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7901 - val_loss: 0.3361 - val_accuracy: 0.8974\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7901 - val_loss: 0.3338 - val_accuracy: 0.8974\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7915 - val_loss: 0.3347 - val_accuracy: 0.8974\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7901 - val_loss: 0.3351 - val_accuracy: 0.8974\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7901 - val_loss: 0.3344 - val_accuracy: 0.8974\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7874 - val_loss: 0.3349 - val_accuracy: 0.8974\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7901 - val_loss: 0.3330 - val_accuracy: 0.8974\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7901 - val_loss: 0.3340 - val_accuracy: 0.8974\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7915 - val_loss: 0.3363 - val_accuracy: 0.8974\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7901 - val_loss: 0.3349 - val_accuracy: 0.8974\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7929 - val_loss: 0.3361 - val_accuracy: 0.8974\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7901 - val_loss: 0.3346 - val_accuracy: 0.8974\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7874 - val_loss: 0.3343 - val_accuracy: 0.8974\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7860 - val_loss: 0.3353 - val_accuracy: 0.8974\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7901 - val_loss: 0.3344 - val_accuracy: 0.8974\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7888 - val_loss: 0.3346 - val_accuracy: 0.8974\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7874 - val_loss: 0.3359 - val_accuracy: 0.8974\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7860 - val_loss: 0.3353 - val_accuracy: 0.8974\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7888 - val_loss: 0.3341 - val_accuracy: 0.8974\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7874 - val_loss: 0.3344 - val_accuracy: 0.8974\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7915 - val_loss: 0.3352 - val_accuracy: 0.8974\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7888 - val_loss: 0.3358 - val_accuracy: 0.8974\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7860 - val_loss: 0.3346 - val_accuracy: 0.8974\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7888 - val_loss: 0.3350 - val_accuracy: 0.8974\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7888 - val_loss: 0.3321 - val_accuracy: 0.8974\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7860 - val_loss: 0.3345 - val_accuracy: 0.8974\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7888 - val_loss: 0.3378 - val_accuracy: 0.8718\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7874 - val_loss: 0.3337 - val_accuracy: 0.8974\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7888 - val_loss: 0.3344 - val_accuracy: 0.8974\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7874 - val_loss: 0.3342 - val_accuracy: 0.8974\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7888 - val_loss: 0.3362 - val_accuracy: 0.8974\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7874 - val_loss: 0.3350 - val_accuracy: 0.8974\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7874 - val_loss: 0.3329 - val_accuracy: 0.8974\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7874 - val_loss: 0.3358 - val_accuracy: 0.8974\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7888 - val_loss: 0.3340 - val_accuracy: 0.8974\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7860 - val_loss: 0.3334 - val_accuracy: 0.8974\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7915 - val_loss: 0.3326 - val_accuracy: 0.8974\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7901 - val_loss: 0.3359 - val_accuracy: 0.8974\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7888 - val_loss: 0.3340 - val_accuracy: 0.8974\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7874 - val_loss: 0.3341 - val_accuracy: 0.8974\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7860 - val_loss: 0.3345 - val_accuracy: 0.8974\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7874 - val_loss: 0.3346 - val_accuracy: 0.8974\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7846 - val_loss: 0.3331 - val_accuracy: 0.8974\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7874 - val_loss: 0.3343 - val_accuracy: 0.8974\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7901 - val_loss: 0.3344 - val_accuracy: 0.8974\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7901 - val_loss: 0.3321 - val_accuracy: 0.8974\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7888 - val_loss: 0.3322 - val_accuracy: 0.8974\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7860 - val_loss: 0.3350 - val_accuracy: 0.8974\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7860 - val_loss: 0.3329 - val_accuracy: 0.8974\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7846 - val_loss: 0.3337 - val_accuracy: 0.8974\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7860 - val_loss: 0.3322 - val_accuracy: 0.8974\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7860 - val_loss: 0.3348 - val_accuracy: 0.8974\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7888 - val_loss: 0.3342 - val_accuracy: 0.8974\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7901 - val_loss: 0.3334 - val_accuracy: 0.8974\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7888 - val_loss: 0.3340 - val_accuracy: 0.8974\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7901 - val_loss: 0.3322 - val_accuracy: 0.8974\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7874 - val_loss: 0.3332 - val_accuracy: 0.8974\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7860 - val_loss: 0.3332 - val_accuracy: 0.8974\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7888 - val_loss: 0.3318 - val_accuracy: 0.8974\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7888 - val_loss: 0.3340 - val_accuracy: 0.8974\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7860 - val_loss: 0.3333 - val_accuracy: 0.8974\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7874 - val_loss: 0.3328 - val_accuracy: 0.8974\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7901 - val_loss: 0.3327 - val_accuracy: 0.8974\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7860 - val_loss: 0.3331 - val_accuracy: 0.8974\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7874 - val_loss: 0.3341 - val_accuracy: 0.8974\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7860 - val_loss: 0.3332 - val_accuracy: 0.8974\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7901 - val_loss: 0.3322 - val_accuracy: 0.8974\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7874 - val_loss: 0.3341 - val_accuracy: 0.8974\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7874 - val_loss: 0.3346 - val_accuracy: 0.8974\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7860 - val_loss: 0.3331 - val_accuracy: 0.8974\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7888 - val_loss: 0.3338 - val_accuracy: 0.8974\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7860 - val_loss: 0.3331 - val_accuracy: 0.8974\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7860 - val_loss: 0.3318 - val_accuracy: 0.8974\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7901 - val_loss: 0.3348 - val_accuracy: 0.8718\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7874 - val_loss: 0.3332 - val_accuracy: 0.8974\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7846 - val_loss: 0.3328 - val_accuracy: 0.8974\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7860 - val_loss: 0.3335 - val_accuracy: 0.8974\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7874 - val_loss: 0.3324 - val_accuracy: 0.8974\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7888 - val_loss: 0.3311 - val_accuracy: 0.8974\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.1853011 , -0.16705617],\n",
      "       [ 0.8872879 , -0.50075805],\n",
      "       [-0.0090089 ,  0.4752642 ],\n",
      "       [-0.2567702 , -0.48094907],\n",
      "       [ 0.16681965,  0.48544857],\n",
      "       [ 0.49007928, -0.2862622 ],\n",
      "       [ 0.2708094 , -0.20381635],\n",
      "       [-0.32194844, -1.3257006 ]], dtype=float32), array([ 1.0272596 , -0.03123579], dtype=float32), array([[ 1.0328922 , -0.18846364, -0.17366289],\n",
      "       [ 1.4819751 ,  0.7369537 ,  0.890846  ]], dtype=float32), array([0.52319324, 0.45933142, 0.41602865], dtype=float32), array([[ 0.8150945 ,  0.68114865],\n",
      "       [ 0.9946064 , -1.0924143 ],\n",
      "       [ 0.8586195 , -0.18578967]], dtype=float32), array([0.22666015, 0.21374428], dtype=float32), array([[-0.6309206],\n",
      "       [ 1.5048292]], dtype=float32), array([-0.25969297], dtype=float32)]\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "[0.92 0.07 0.03 0.67 0.11 0.01 0.82 0.83 0.48 0.29 0.76 0.89 0.28 0.21\n",
      " 0.23 0.26 0.84 0.01 0.23 0.37 0.67 0.23 0.26 0.23 0.01 0.4  0.01 0.87\n",
      " 0.06 0.09 0.45 0.21 0.03 0.58 0.04 0.77 0.48 0.01 0.39]\n",
      "[1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
      " 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26,  2],\n",
       "       [ 2,  9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pima = pd.read_csv(\"diabetes.csv\")\n",
    "pima.head()\n",
    "\n",
    "# split dataset in features and target variable\n",
    "feature_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','Insulin','BMI','DiabetesPedigreeFunction', 'Age']\n",
    "Xraw = pima[feature_cols] # Features\n",
    "y = pima.Outcome # Target variable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(Xraw)\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.05,random_state=0)\n",
    "print(y_test)\n",
    "\n",
    "# neural network\n",
    "model = tf.keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=(8,)))\n",
    "model.add(keras.layers.Dense(3,activation='relu'))\n",
    "model.add(keras.layers.Dense(2,activation='relu'))\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_1 = model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test))\n",
    "\n",
    "# visualization of lossfunction\n",
    "loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "SKIP = 10\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Find the weights of the model\n",
    "weights = model.get_weights()\n",
    "print(weights)\n",
    "\n",
    "# Saving the array in a text file\n",
    "file = open(\"hyper_param.txt\", \"w+\")\n",
    "content = str(weights)\n",
    "file.write(content)\n",
    "file.close()\n",
    "\n",
    "#y_pred = model.predict(X_test)\n",
    "# extract the predicted probabilities\n",
    "p_pred = model.predict(X_test)\n",
    "p_pred = p_pred.flatten()\n",
    "print(p_pred.round(2))\n",
    "# [1. 0.01 0.91 0.87 0.06 0.95 0.24 0.58 0.78 ...\n",
    "\n",
    "# extract the predicted class labels\n",
    "y_pred = np.where(p_pred > 0.5, 1, 0)\n",
    "print(y_pred)\n",
    "\n",
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e1cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1a492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
